# Thesis

## Papers

- [Attention is all you need (2017)](./papers/summary/Attention%20is%20all%20you%20need%20(2017).md)
- [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (2019)](./papers/summary/BERT%3A%20Pre-training%20of%20Deep%20Bidirectional%20Transformers%20for%20Language%20Understanding%20(2019).md)
- [Code Llama: Open Foundation Models for Code (2023)](./papers/summary/Code%20Llama%3A%20Open%20Foundation%20Models%20for%20Code%20(2023).md)
- [GRU : Learning Phrase Representations using RNN Encoderâ€“Decoder for Statistical Machine Translation (2014)](./papers/summary/GRU%20%3A%20Learning%20Phrase%20Representations%20using%20RNN%20Encoder%E2%80%93Decoder%20for%20Statistical%20Machine%20Translation%20%282014%29.md)
- [Long Short Term Memory (1997)](./papers/summary/Long%20Short%20Term%20Memory%20%281997%29.md)
- [RWKV : Reinventing RNNs for the Transformer Era (2023)](./papers/summary/RWKV%3A%20Reinventing%20RNNs%20for%20the%20Transformer%20Era%20%282023%29.md)
