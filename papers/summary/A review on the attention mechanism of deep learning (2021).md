### A review on the attention mechanism of deep learning of deep learning (2021)

![Paper](https://www.sciencedirect.com/science/article/abs/pii/S092523122100477X)

1. **Mécanismes d'Attention** : L'article définit l'attention dans le contexte de l'apprentissage profond comme une méthode inspirée par les processus cognitifs humains, où l'accent est mis sur certaines parties de l'information tout en ignorant les autres. Ce mécanisme a été largement appliqué dans diverses applications d'apprentissage profond pour améliorer l'efficacité et la précision.

2. **Classification des Modèles d'Attention** : Les modèles d'attention sont classés en fonction de quatre critères : la douceur de l'attention, les formes de caractéristique d'entrée, la représentation d'entrée et la représentation de sortie. Cette classification aide à comprendre les différentes approches et leur adéquation pour diverses tâches.

3. **Architectures de Réseaux** : L'article résume les architectures de réseaux qui intègrent des mécanismes d'attention, indiquant comment ces architectures sont adaptées pour tirer parti des avantages de l'attention pour améliorer les performances.

4. **Applications** : La revue couvre une gamme d'applications en vision par ordinateur et en traitement du langage naturel où les mécanismes d'attention ont été appliqués avec succès, démontrant leur polyvalence et leur efficacité.

5. **Interprétabilité** : L'un des avantages significatifs des mécanismes d'attention est leur potentiel à apporter de l'interprétabilité aux modèles d'apprentissage profond. Bien qu'il y ait une certaine controverse sur la fiabilité de l'attention pour expliquer le comportement du modèle, elle offre une manière intuitive de comprendre les décisions du modèle dans une certaine mesure.
