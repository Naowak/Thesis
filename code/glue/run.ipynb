{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CoLA\n",
    "\n",
    "Juger si une phrase anglaise est grammaticalement correcte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   truth                                           sentence\n",
      "0      1  Our friends won't buy this analysis, let alone...\n",
      "1      1  One more pseudo generalization and I'm giving up.\n",
      "   index                               sentence\n",
      "0      0          Bill whistled past the house.\n",
      "1      1  The car honked its way down the road.\n"
     ]
    }
   ],
   "source": [
    "cola_train = pd.read_csv('./CoLA/train.tsv',sep='\\t', names=['_', 'truth', 'unknown', 'sentence']).drop(['_','unknown'], axis=1)\n",
    "cola_test = pd.read_csv('./CoLA/test.tsv',sep='\\t')\n",
    "\n",
    "print(cola_train.head(2))\n",
    "print(cola_test.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNLI\n",
    "\n",
    "Comprendre si une phrase est une implication, une contradiction ou neutre par rapport à une autre phrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           sentence1  \\\n",
      "0  Conceptually cream skimming has two basic dime...   \n",
      "1  you know during the season and i guess at at y...   \n",
      "\n",
      "                                           sentence2  gold_label  \n",
      "0  Product and geography are what make cream skim...     neutral  \n",
      "1  You lose the things to the following level if ...  entailment  \n",
      "   index                                          sentence1  \\\n",
      "0      0  Hierbas, ans seco, ans dulce, and frigola are ...   \n",
      "1      1  The extent of the behavioral effects would dep...   \n",
      "\n",
      "                                           sentence2  \n",
      "0           Hierbas is a name worth looking out for.  \n",
      "1  Many people would be very unhappy to loose con...  \n",
      "   index                                          sentence1  \\\n",
      "0      0   What have you decided, what are you going to do?   \n",
      "1      1  Women's clothing is characterized by great div...   \n",
      "\n",
      "                                           sentence2  \n",
      "0                           So what's your decision?  \n",
      "1  Men's clothing typically has the most stylisti...  \n"
     ]
    }
   ],
   "source": [
    "mnli_train = pd.read_csv('./MNLI/train.tsv', sep='\\t', on_bad_lines='skip')[['sentence1', 'sentence2', 'gold_label']]\n",
    "mnli_test_matched = pd.read_csv('./MNLI/test_matched.tsv', sep='\\t')[['index', 'sentence1', 'sentence2']]\n",
    "mnli_test_mismatched = pd.read_csv('./MNLI/test_mismatched.tsv', sep='\\t')[['index', 'sentence1', 'sentence2']]\n",
    "\n",
    "print(mnli_train.head(2))\n",
    "print(mnli_test_matched.head(2))\n",
    "print(mnli_test_mismatched.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QNLI\n",
    "\n",
    "Identifier si une réponse est une bonne réponse à une question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index                                           question  \\\n",
      "0      0           When did the third Digimon series begin?   \n",
      "1      1  Which missile batteries often have individual ...   \n",
      "\n",
      "                                            sentence           label  \n",
      "0  Unlike the two seasons before it and most of t...  not_entailment  \n",
      "1  When MANPADS is operated by specialists, batte...  not_entailment  \n",
      "   index                                           question  \\\n",
      "0      0  What organization is devoted to Jihad against ...   \n",
      "1      1  In what century was the Yarrow-Schlick-Tweedy ...   \n",
      "\n",
      "                                            sentence  \n",
      "0  For some decades prior to the First Palestine ...  \n",
      "1  In the late 19th century, the Yarrow-Schlick-T...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_8/z8rcf_ns4k9f2rw5zchj85mw0000gn/T/ipykernel_53365/93450365.py:2: ParserWarning: Skipping line 851: expected 3 fields, saw 4\n",
      "\n",
      "  qnli_test = pd.read_csv('./QNLI/test.tsv', sep='\\t', on_bad_lines='warn')\n"
     ]
    }
   ],
   "source": [
    "qnli_train = pd.read_csv('./QNLI/train.tsv', sep='\\t', on_bad_lines='skip')\n",
    "qnli_test = pd.read_csv('./QNLI/test.tsv', sep='\\t', on_bad_lines='warn')\n",
    "\n",
    "print(qnli_train.head(2))\n",
    "print(qnli_test.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dtrvenv",
   "language": "python",
   "name": "dtrvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
